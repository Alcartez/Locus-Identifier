{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.Blast import NCBIWWW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_data = open(\"blast_example.fasta\").read() \n",
    "result_handle = NCBIWWW.qblast(\"blastn\", \"nt\", sequence_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blastn -db alun -query search.fsa -out results.xml -outfmt 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.Blast.Applications import NcbiblastnCommandline \n",
    "blastn_cline = NcbiblastnCommandline(query = \"search.fsa\", db = \"local_alu_db\\local_alu_db\", outfmt = 5, out = \"results.xml\") \n",
    "stdout, stderr = blastn_cline()\n",
    "print(stdout)\n",
    "print(stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO \n",
    "from Bio.Blast import NCBIWWW\n",
    "seq_record = next(SeqIO.parse(open('blast_input.fasta'),'fasta')) \n",
    "print(seq_record.id)\n",
    "result_handle = NCBIWWW.qblast(\"blastn\", \"nt\", seq_record.seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results.xml', 'w') as save_file: \n",
    "   blast_results = result_handle.read() \n",
    "   save_file.write(blast_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "cmd = \"blastn -db alun -query search.fsa -out results_aluuuuuuuu.xml -outfmt 5\"\n",
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.Blast import NCBIXML\n",
    "E_VALUE_THRESH = 1e-20 \n",
    "for alignment in NCBIXML.parse(open(\"blast_input.xml\")):\n",
    "    for hsp in alignment.hsps:\n",
    "        if hsp.expect < E_VALUE_THRESH:\n",
    "            print(\"****Alignment****\")\n",
    "            print(\"sequence:\", alignment.title)\n",
    "            print(\"length:\", alignment.length)\n",
    "            print(\"e value:\", hsp.expect)\n",
    "            print(hsp.query[0:100] + \"...\")\n",
    "            print(hsp.match[0:100] + \"...\")\n",
    "            print(hsp.sbjct[0:100] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Local Database ...\n",
      "CMD :  makeblastdb -out local_alu_db -dbtype nucl -in 13396_Alu_Elements.fsa\n"
     ]
    }
   ],
   "source": [
    "############################################# ALU FINDER ####################################################################\n",
    "###### MAKE LOCAL DATABASE ######\n",
    "from Bio.Blast.Applications import NcbimakeblastdbCommandline\n",
    "db_fasta_raw_filename = \"13396_Alu_Elements.fsa\"\n",
    "local_dbname = \"local_alu_db\"\n",
    "print(\"Creating Local Database ...\")\n",
    "\n",
    "makeblastdb_cline = NcbimakeblastdbCommandline(dbtype=\"nucl\", input_file= db_fasta_raw_filename ,out = local_dbname )\n",
    "print(\"CMD : \" , makeblastdb_cline)\n",
    "stdout,stderr = makeblastdb_cline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 = pairwise\n",
      "1 = query-anchored showing identities\n",
      "2 = query-anchored no identities\n",
      "3 = flat query-anchored, show identities\n",
      "4 = flat query-anchored, no identities\n",
      "5 = XML Blast output\n",
      "6 = tabular\n",
      "7 = tabular with comment lines\n",
      "8 = Text ASN.1\n",
      "9 = Binary ASN.1\n",
      "10 = Comma-separated values\n",
      "\n",
      " Result :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Bio.Blast.Applications import NcbiblastnCommandline\n",
    "import subprocess\n",
    "\n",
    "seq = \"blast_input\" \n",
    "\n",
    "print(\"0 = pairwise\")\n",
    "print(\"1 = query-anchored showing identities\")\n",
    "print(\"2 = query-anchored no identities\")\n",
    "print(\"3 = flat query-anchored, show identities\")\n",
    "print(\"4 = flat query-anchored, no identities\")\n",
    "print(\"5 = XML Blast output\")\n",
    "print(\"6 = tabular\")\n",
    "print(\"7 = tabular with comment lines\")\n",
    "print(\"8 = Text ASN.1\")\n",
    "print(\"9 = Binary ASN.1\")\n",
    "print(\"10 = Comma-separated values\")\n",
    "\n",
    "# command_line = ['blastn','-query',\n",
    "#                seq + '.fasta','-out',\n",
    "#                seq + '_blout', '-outfmt',\n",
    "#                '6','-db','local_alu_db']\n",
    "\n",
    "command_line = \"blastn -db local_alu_db -query \" + seq + \".fasta \" +\"-out \" + seq + \".xml -outfmt 5 \"\n",
    "\n",
    "\n",
    "print(\"\\n Result :\")\n",
    "subprocess.call(command_line)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_blast(resultfile): #takes in the BLAST result, outputs list that can be made into csv rows\n",
    "    from Bio.Blast import NCBIXML\n",
    "    result_handle = open(resultfile)\n",
    "    blast_records = NCBIXML.parse(result_handle)\n",
    "    csv_list = []\n",
    "    \n",
    "    header = [  'Query',\n",
    "                'Name', 'Length', 'Score', 'Expect',\n",
    "                'QueryStart', 'QueryEnd',\n",
    "                'SubjectStart', 'SubjectEnd'\n",
    "            ]\n",
    "    \n",
    "    csv_list.append(header)\n",
    "    count = 0\n",
    "    for blast_record in blast_records:\n",
    "        '''help(blast_record.alignments[0].hsps[0])''' # these give help info for the parts \n",
    "        '''help(blast_record.alignments[0])        '''\n",
    "        count +=1\n",
    "        \n",
    "        query = blast_record.query\n",
    "        for alignment in blast_record.alignments:\n",
    "\n",
    "            name = alignment.title\n",
    "            length = alignment.length\n",
    "    \n",
    "            hsp = alignment.hsps[0] # I don't know if we will ever have more than one, so might as well take the first one.\n",
    "            score = hsp.score\n",
    "            expect = hsp.expect\n",
    "            querystart = hsp.query_start\n",
    "            queryend = hsp.query_end\n",
    "            subjectstart = hsp.sbjct_start\n",
    "            subjectend = hsp.sbjct_end\n",
    "            row = [query,name,length,score,expect,querystart,queryend,subjectstart,subjectend]\n",
    "            csv_list.append(row)\n",
    "            \n",
    "    result_handle.close()\n",
    "    return csv_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Query', 'Name', 'Length', 'Score', 'Expect', 'QueryStart', 'QueryEnd', 'SubjectStart', 'SubjectEnd']\n",
      "['Example 1', 'gnl|BL_ORD_ID|5 1:006820988:fw:REF-plus:GGCCGGGCGC:305', 317, 116.0, 6.56851e-58, 341, 625, 2, 296]\n",
      "['Example 1', 'gnl|BL_ORD_ID|37 1:028673658:fw:REF-plus:GGCCGGGCGC:338', 350, 106.0, 2.37923e-52, 341, 629, 2, 296]\n",
      "['Example 1', 'gnl|BL_ORD_ID|48 1:036261192:fw:REF-plus:GGCCGGGCGC:323', 335, 87.0, 8.67916e-42, 351, 627, 12, 298]\n",
      "['Example 1', 'gnl|BL_ORD_ID|6 1:006953058:fw:REF-plus:GGCCGGGCGC:291', 303, 82.0, 5.22351e-39, 341, 530, 2, 192]\n",
      "['Example 1', 'gnl|BL_ORD_ID|11 1:009826434:fw:REF-plus:GGCCGGGCGC:285', 297, 72.0, 1.89205e-33, 31, 306, 6, 287]\n",
      "['Example 1', 'gnl|BL_ORD_ID|14 1:010614064:fw:REF-plus:GGCCGGGCGC:326', 338, 63.0, 1.90548e-28, 143, 320, 133, 314]\n",
      "['Example 1', 'gnl|BL_ORD_ID|133 1:112302314:fw:REF-plus:GGCCGGGCGC:311', 323, 55.0, 5.33556e-24, 93, 318, 71, 297]\n",
      "['Example 1', 'gnl|BL_ORD_ID|74 1:062390602:fw:REF-plus:GGCCGGGCGC:344', 356, 52.0, 2.48239e-22, 178, 318, 143, 285]\n",
      "['Example 1', 'gnl|BL_ORD_ID|42 1:031269617:fw:REF-plus:GGCCGGGCGC:283', 295, 52.0, 2.48239e-22, 143, 306, 120, 287]\n",
      "['Example 1', 'gnl|BL_ORD_ID|13 1:009948357:fw:REF-plus:GGCCGGGCGC:271', 283, 52.0, 2.48239e-22, 199, 318, 148, 264]\n",
      "['Example 1', 'gnl|BL_ORD_ID|31 1:026853230:fw:REF-plus:GGCCGGGCGC:301', 313, 51.0, 8.92827e-22, 93, 318, 71, 295]\n",
      "['Example 1', 'gnl|BL_ORD_ID|21 1:021134892:fw:REF-plus:GGCCGGGCGC:293', 305, 51.0, 8.92827e-22, 93, 313, 71, 293]\n",
      "['Example 1', 'gnl|BL_ORD_ID|165 1:164427556:fw:REF-plus:GGCCGGGCGC:308', 320, 49.0, 1.15495e-20, 130, 318, 107, 297]\n",
      "['Example 1', 'gnl|BL_ORD_ID|198 1:197497708:fw:REF-plus:GGCCGGGCGC:297', 309, 48.0, 4.15392e-20, 130, 318, 107, 295]\n",
      "['Example 1', 'gnl|BL_ORD_ID|23 1:021700377:fw:REF-plus:GGCCGGGCGC:318', 330, 48.0, 4.15392e-20, 134, 318, 111, 297]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "blast_ot =  \"blast_input.xml\"\n",
    "output_csv = parse_blast(blast_ot)\n",
    "filename = \"output.csv\"\n",
    "with open(filename, 'w') as csvfile: \n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    for line in output_csv:\n",
    "        print(line)\n",
    "        csvwriter.writerow(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Start Position :  340 \n",
      " End Position :  624 \n",
      " Deleted Element :  GCCAGGTGTGGTGGCTCACGCCTGTAATCCCACCGCTTTGGGAGGCTGAGTCAGATCACCTGAGGTTAGGAATTTGGGACCAGCCTGGCCAACATGGCGACACCCCAGTCTCTACTAATAACACAAAAAATTAGCCAGGTGTGCTGGTGCATGTCTGTAATCCCAGCTACTCAGGAGGCTGAGGCATGAGAATTGCTCACGAGGCGGAGGTTGTAGTGAGCTGAGATCGTGGCACTGTACTCCAGCCTGGCGACAGAGGGAGAACCCATGTCAAAAACAAAAAA \n",
      "\n",
      "\n",
      " Start Position :  340 \n",
      " End Position :  628 \n",
      " Deleted Element :  GCCAGGTGTGGTGGCTCACGCCTGTAATCCCACCGCTTTGGGAGGCTGAGTCAGATCACCTGAGGTTAGGAATTTGGGACCAGCCTGGCCAACATGGCGACACCCCAGTCTCTACTAATAACACAAAAAATTAGCCAGGTGTGCTGGTGCATGTCTGTAATCCCAGCTACTCAGGAGGCTGAGGCATGAGAATTGCTCACGAGGCGGAGGTTGTAGTGAGCTGAGATCGTGGCACTGTACTCCAGCCTGGCGACAGAGGGAGAACCCATGTCAAAAACAAAAAAAGAC \n",
      "\n",
      "\n",
      " Start Position :  350 \n",
      " End Position :  626 \n",
      " Deleted Element :  GTGGCTCACGCCTGTAATCCCACCGCTTTGGGAGGCTGAGTCAGATCACCTGAGGTTAGGAATTTGGGACCAGCCTGGCCAACATGGCGACACCCCAGTCTCTACTAATAACACAAAAAATTAGCCAGGTGTGCTGGTGCATGTCTGTAATCCCAGCTACTCAGGAGGCTGAGGCATGAGAATTGCTCACGAGGCGGAGGTTGTAGTGAGCTGAGATCGTGGCACTGTACTCCAGCCTGGCGACAGAGGGAGAACCCATGTCAAAAACAAAAAAAG \n",
      "\n",
      "\n",
      " Start Position :  340 \n",
      " End Position :  529 \n",
      " Deleted Element :  GCCAGGTGTGGTGGCTCACGCCTGTAATCCCACCGCTTTGGGAGGCTGAGTCAGATCACCTGAGGTTAGGAATTTGGGACCAGCCTGGCCAACATGGCGACACCCCAGTCTCTACTAATAACACAAAAAATTAGCCAGGTGTGCTGGTGCATGTCTGTAATCCCAGCTACTCAGGAGGCTGAGGCATGA \n",
      "\n",
      "\n",
      " Start Position :  30 \n",
      " End Position :  305 \n",
      " Deleted Element :  GGCACTGTGGCTCATGCTGAAATCCCAGCACGGCGGAGGACGGCGGAAGATTGCTTGAGCCTAGGAGTTTGCGACCAGCCTGGGTGACATAGGGAGATGCCTGTCTCTACGCAAAAGAAAAAAAAAATAGCTCTGCTGGTGGTGCATGCCTATAGTCTCAGCTATCAGGAGGCTGGGACAGGAGGATCACTTGGGCCCGGGAGTTGAGGCTGTGGTGAGCCACGATCACACCACTGCACTCCAGCCTGGGTGACAGAGCAAGACCCTGTCTCAAA \n",
      "\n",
      "\n",
      " Start Position :  142 \n",
      " End Position :  319 \n",
      " Deleted Element :  AAAAGAAAAAAAAAATAGCTCTGCTGGTGGTGCATGCCTATAGTCTCAGCTATCAGGAGGCTGGGACAGGAGGATCACTTGGGCCCGGGAGTTGAGGCTGTGGTGAGCCACGATCACACCACTGCACTCCAGCCTGGGTGACAGAGCAAGACCCTGTCTCAAAACAAACAAATAAAG \n",
      "\n",
      "\n",
      " Start Position :  92 \n",
      " End Position :  317 \n",
      " Deleted Element :  AGGAGTTTGCGACCAGCCTGGGTGACATAGGGAGATGCCTGTCTCTACGCAAAAGAAAAAAAAAATAGCTCTGCTGGTGGTGCATGCCTATAGTCTCAGCTATCAGGAGGCTGGGACAGGAGGATCACTTGGGCCCGGGAGTTGAGGCTGTGGTGAGCCACGATCACACCACTGCACTCCAGCCTGGGTGACAGAGCAAGACCCTGTCTCAAAACAAACAAATAA \n",
      "\n",
      "\n",
      " Start Position :  177 \n",
      " End Position :  317 \n",
      " Deleted Element :  GCCTATAGTCTCAGCTATCAGGAGGCTGGGACAGGAGGATCACTTGGGCCCGGGAGTTGAGGCTGTGGTGAGCCACGATCACACCACTGCACTCCAGCCTGGGTGACAGAGCAAGACCCTGTCTCAAAACAAACAAATAA \n",
      "\n",
      "\n",
      " Start Position :  142 \n",
      " End Position :  305 \n",
      " Deleted Element :  AAAAGAAAAAAAAAATAGCTCTGCTGGTGGTGCATGCCTATAGTCTCAGCTATCAGGAGGCTGGGACAGGAGGATCACTTGGGCCCGGGAGTTGAGGCTGTGGTGAGCCACGATCACACCACTGCACTCCAGCCTGGGTGACAGAGCAAGACCCTGTCTCAAA \n",
      "\n",
      "\n",
      " Start Position :  198 \n",
      " End Position :  317 \n",
      " Deleted Element :  GAGGCTGGGACAGGAGGATCACTTGGGCCCGGGAGTTGAGGCTGTGGTGAGCCACGATCACACCACTGCACTCCAGCCTGGGTGACAGAGCAAGACCCTGTCTCAAAACAAACAAATAA \n",
      "\n",
      "\n",
      " Start Position :  92 \n",
      " End Position :  317 \n",
      " Deleted Element :  AGGAGTTTGCGACCAGCCTGGGTGACATAGGGAGATGCCTGTCTCTACGCAAAAGAAAAAAAAAATAGCTCTGCTGGTGGTGCATGCCTATAGTCTCAGCTATCAGGAGGCTGGGACAGGAGGATCACTTGGGCCCGGGAGTTGAGGCTGTGGTGAGCCACGATCACACCACTGCACTCCAGCCTGGGTGACAGAGCAAGACCCTGTCTCAAAACAAACAAATAA \n",
      "\n",
      "\n",
      " Start Position :  92 \n",
      " End Position :  312 \n",
      " Deleted Element :  AGGAGTTTGCGACCAGCCTGGGTGACATAGGGAGATGCCTGTCTCTACGCAAAAGAAAAAAAAAATAGCTCTGCTGGTGGTGCATGCCTATAGTCTCAGCTATCAGGAGGCTGGGACAGGAGGATCACTTGGGCCCGGGAGTTGAGGCTGTGGTGAGCCACGATCACACCACTGCACTCCAGCCTGGGTGACAGAGCAAGACCCTGTCTCAAAACAAACA \n",
      "\n",
      "\n",
      " Start Position :  129 \n",
      " End Position :  317 \n",
      " Deleted Element :  CCTGTCTCTACGCAAAAGAAAAAAAAAATAGCTCTGCTGGTGGTGCATGCCTATAGTCTCAGCTATCAGGAGGCTGGGACAGGAGGATCACTTGGGCCCGGGAGTTGAGGCTGTGGTGAGCCACGATCACACCACTGCACTCCAGCCTGGGTGACAGAGCAAGACCCTGTCTCAAAACAAACAAATAA \n",
      "\n",
      "\n",
      " Start Position :  129 \n",
      " End Position :  317 \n",
      " Deleted Element :  CCTGTCTCTACGCAAAAGAAAAAAAAAATAGCTCTGCTGGTGGTGCATGCCTATAGTCTCAGCTATCAGGAGGCTGGGACAGGAGGATCACTTGGGCCCGGGAGTTGAGGCTGTGGTGAGCCACGATCACACCACTGCACTCCAGCCTGGGTGACAGAGCAAGACCCTGTCTCAAAACAAACAAATAA \n",
      "\n",
      "\n",
      " Start Position :  133 \n",
      " End Position :  317 \n",
      " Deleted Element :  TCTCTACGCAAAAGAAAAAAAAAATAGCTCTGCTGGTGGTGCATGCCTATAGTCTCAGCTATCAGGAGGCTGGGACAGGAGGATCACTTGGGCCCGGGAGTTGAGGCTGTGGTGAGCCACGATCACACCACTGCACTCCAGCCTGGGTGACAGAGCAAGACCCTGTCTCAAAACAAACAAATAA \n",
      "\n",
      "\n",
      " Sequence :  ATAGGATAGATTAGGATAGAGAGAGAGGCTGGCACTGTGGCTCATGCTGAAATCCCAGCACGGCGGAGGACGGCGGAAGATTGCTTGAGCCTAGGAGTTTGCGACCAGCCTGGGTGACATAGGGAGATGCCTGAGATATATATATATTAGGGGATAGCCAGGTGTGGTGGCTCACGCCTGTAATCCCACCGCTTTGGGAGGCTGAGTCAGATCACCTGAGGTTAGGAATTTGGGACCAGCCTGGCCAACATGGCGACACCCCAGTCTCTACTAATAACACAAAAAATTAGCCAGGTGTGCTGGTGCATGTCTGTAATCCCAGCTACTCAGGAGGCTGAGGCATGAGAATTGCTCACGAGGCGGAGGTTGTAGTGAGCTGAGATCGTGGCACTGTACTCCAGCCTGGCGACAGAGGGAGAACCCATGTCAAAAACAAAAAAAGACACCACCAAAGGTCAAAGCATA\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from Bio import SeqIO\n",
    "\n",
    "output_csv = pd.read_csv(\"output.csv\")\n",
    "Alu_start_position_list = output_csv.QueryStart\n",
    "Alu_end_position_list = output_csv.QueryEnd\n",
    "alu_locations_df = pd.DataFrame(list(zip(Alu_start_position_list, Alu_end_position_list)),columns =['Start Position', 'End Position'])\n",
    "seq_record = SeqIO.parse(open('blast_input.fasta'),'fasta')\n",
    "\n",
    "# Removing Alu Element and Zipping it together\n",
    "\n",
    "for seq_object in seq_record :\n",
    "    for i in range(0,alu_locations_df.shape[0]):\n",
    "        seq = str(seq_object.seq)\n",
    "        Query_Start = alu_locations_df.at[i, \"Start Position\"] - 1\n",
    "        Query_End = alu_locations_df.at[i, \"End Position\"] - 1\n",
    "        print(\"\\n Start Position : \" , Query_Start , \"\\n End Position : \" , Query_End , \"\\n Deleted Element : \" , seq[Query_Start:Query_End] , \"\\n\")\n",
    "        seq = seq.replace(seq[Query_Start:Query_End], '')\n",
    "    print(\"\\n Sequence : \" , seq) \n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\papac\\AppData\\Local\\Temp\\ipykernel_5588\\1007790438.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  Locus_df = Locus_df.append({'Locus Start Position' : max(0,Query_Start-100), 'Locus End Position' : min(Query_End + 100 , len(seq)), 'Locus' : Locus, 'Query Match' : Query_Match}, ignore_index = True)\n",
      "C:\\Users\\papac\\AppData\\Local\\Temp\\ipykernel_5588\\1007790438.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  Locus_df = Locus_df.append({'Locus Start Position' : max(0,Query_Start-100), 'Locus End Position' : min(Query_End + 100 , len(seq)), 'Locus' : Locus, 'Query Match' : Query_Match}, ignore_index = True)\n",
      "C:\\Users\\papac\\AppData\\Local\\Temp\\ipykernel_5588\\1007790438.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  Locus_df = Locus_df.append({'Locus Start Position' : max(0,Query_Start-100), 'Locus End Position' : min(Query_End + 100 , len(seq)), 'Locus' : Locus, 'Query Match' : Query_Match}, ignore_index = True)\n",
      "C:\\Users\\papac\\AppData\\Local\\Temp\\ipykernel_5588\\1007790438.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  Locus_df = Locus_df.append({'Locus Start Position' : max(0,Query_Start-100), 'Locus End Position' : min(Query_End + 100 , len(seq)), 'Locus' : Locus, 'Query Match' : Query_Match}, ignore_index = True)\n",
      "C:\\Users\\papac\\AppData\\Local\\Temp\\ipykernel_5588\\1007790438.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  Locus_df = Locus_df.append({'Locus Start Position' : max(0,Query_Start-100), 'Locus End Position' : min(Query_End + 100 , len(seq)), 'Locus' : Locus, 'Query Match' : Query_Match}, ignore_index = True)\n",
      "C:\\Users\\papac\\AppData\\Local\\Temp\\ipykernel_5588\\1007790438.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  Locus_df = Locus_df.append({'Locus Start Position' : max(0,Query_Start-100), 'Locus End Position' : min(Query_End + 100 , len(seq)), 'Locus' : Locus, 'Query Match' : Query_Match}, ignore_index = True)\n",
      "C:\\Users\\papac\\AppData\\Local\\Temp\\ipykernel_5588\\1007790438.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  Locus_df = Locus_df.append({'Locus Start Position' : max(0,Query_Start-100), 'Locus End Position' : min(Query_End + 100 , len(seq)), 'Locus' : Locus, 'Query Match' : Query_Match}, ignore_index = True)\n",
      "C:\\Users\\papac\\AppData\\Local\\Temp\\ipykernel_5588\\1007790438.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  Locus_df = Locus_df.append({'Locus Start Position' : max(0,Query_Start-100), 'Locus End Position' : min(Query_End + 100 , len(seq)), 'Locus' : Locus, 'Query Match' : Query_Match}, ignore_index = True)\n",
      "C:\\Users\\papac\\AppData\\Local\\Temp\\ipykernel_5588\\1007790438.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  Locus_df = Locus_df.append({'Locus Start Position' : max(0,Query_Start-100), 'Locus End Position' : min(Query_End + 100 , len(seq)), 'Locus' : Locus, 'Query Match' : Query_Match}, ignore_index = True)\n",
      "C:\\Users\\papac\\AppData\\Local\\Temp\\ipykernel_5588\\1007790438.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  Locus_df = Locus_df.append({'Locus Start Position' : max(0,Query_Start-100), 'Locus End Position' : min(Query_End + 100 , len(seq)), 'Locus' : Locus, 'Query Match' : Query_Match}, ignore_index = True)\n",
      "C:\\Users\\papac\\AppData\\Local\\Temp\\ipykernel_5588\\1007790438.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  Locus_df = Locus_df.append({'Locus Start Position' : max(0,Query_Start-100), 'Locus End Position' : min(Query_End + 100 , len(seq)), 'Locus' : Locus, 'Query Match' : Query_Match}, ignore_index = True)\n",
      "C:\\Users\\papac\\AppData\\Local\\Temp\\ipykernel_5588\\1007790438.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  Locus_df = Locus_df.append({'Locus Start Position' : max(0,Query_Start-100), 'Locus End Position' : min(Query_End + 100 , len(seq)), 'Locus' : Locus, 'Query Match' : Query_Match}, ignore_index = True)\n",
      "C:\\Users\\papac\\AppData\\Local\\Temp\\ipykernel_5588\\1007790438.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  Locus_df = Locus_df.append({'Locus Start Position' : max(0,Query_Start-100), 'Locus End Position' : min(Query_End + 100 , len(seq)), 'Locus' : Locus, 'Query Match' : Query_Match}, ignore_index = True)\n",
      "C:\\Users\\papac\\AppData\\Local\\Temp\\ipykernel_5588\\1007790438.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  Locus_df = Locus_df.append({'Locus Start Position' : max(0,Query_Start-100), 'Locus End Position' : min(Query_End + 100 , len(seq)), 'Locus' : Locus, 'Query Match' : Query_Match}, ignore_index = True)\n",
      "C:\\Users\\papac\\AppData\\Local\\Temp\\ipykernel_5588\\1007790438.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  Locus_df = Locus_df.append({'Locus Start Position' : max(0,Query_Start-100), 'Locus End Position' : min(Query_End + 100 , len(seq)), 'Locus' : Locus, 'Query Match' : Query_Match}, ignore_index = True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from Bio import SeqIO\n",
    "\n",
    "output_csv = pd.read_csv(\"output.csv\")\n",
    "Alu_start_position_list = output_csv.QueryStart\n",
    "Alu_end_position_list = output_csv.QueryEnd\n",
    "alu_locations_df = pd.DataFrame(list(zip(output_csv.Name, output_csv.QueryStart, output_csv.QueryEnd)),columns =['Name' ,'Start Position', 'End Position'])\n",
    "seq_record = SeqIO.parse(open('blast_input.fasta'),'fasta')\n",
    "\n",
    "\n",
    "# Locus Finder\n",
    "\n",
    "Locus_df = pd.DataFrame(columns = ['Locus Start Position', 'Locus End Position' , 'Locus', 'Query Match'])\n",
    "\n",
    "for seq_object in seq_record :\n",
    "    for i in range(0,alu_locations_df.shape[0]):\n",
    "        seq = str(seq_object.seq)\n",
    "        Query_Start = alu_locations_df.at[i, \"Start Position\"] - 1\n",
    "        Query_End = alu_locations_df.at[i, \"End Position\"] - 1\n",
    "        Query_Match = alu_locations_df.at[i, \"Name\"]\n",
    "        Locus_Downsteam = seq[max(0,Query_Start-100):Query_Start]\n",
    "        Locus_Upstream = seq[Query_End + 1:min(Query_End + 100 , len(seq))]\n",
    "        #print(\"\\n Start Position : \" , Query_Start , \"\\n End Position : \" , Query_End ,\"\\n Match : \" , Query_Match ,\"\\n Transposon : \" , seq[Query_Start:Query_End] , \"\\n\")\n",
    "        Locus = Locus_Downsteam + Locus_Upstream\n",
    "        #print(\"\\n Locus : \" , Locus)\n",
    "        Locus_df = Locus_df.append({'Locus Start Position' : max(0,Query_Start-100), 'Locus End Position' : min(Query_End + 100 , len(seq)), 'Locus' : Locus, 'Query Match' : Query_Match}, ignore_index = True)\n",
    "\n",
    "Locus_df.to_csv('LocusIdentifier_Output.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56789\n"
     ]
    }
   ],
   "source": [
    "Str = \"0123456789\"\n",
    "print(Str[5:9+100])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f1e60438be99f3f7920a16f53f5e4171a8d9d8d795881951e5dd5fe0b923b7da"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
